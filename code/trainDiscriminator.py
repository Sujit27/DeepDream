import sys
sys.path.append('../lib/')
from helperFunctions import *

# Created by Sujit Sahoo, 24.11.2019
# sujit.sahoo@fau.de

# Description : Trains a classifier on dream images generated by activation maximization
#               and real images from image net validation set


def main():
    
    #set device to cuda
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Device used to train the discriminator: ", device)

    data_path = '/var/tmp/imageData/'
    realImagescsv = 'realImages.csv'
    dreamImagescsv = 'dreamImages.csv'

    #creates dataset from images in the local drive
    dataset = createDataset(data_path,realImagescsv,dreamImagescsv)

    #split dataset into train and validate
    datasetTrain,datasetValidate = splitData(dataset,0.75)

    numEpochs = 10
    batch_size = 32
    #sampler = sampleDataset(dataset,datasetTrain) # creates sampler according to the ratio of labels in the dataset
    
    # set parameters for dataloader
    #paramsTrain = {'batch_size': batch_size,'shuffle':False,'pin_memory':True,'sampler':sampler}
    paramsTrain = {'batch_size': batch_size,'shuffle':True,'pin_memory':True}
    paramsValidate = {'batch_size': batch_size,'shuffle':True,'pin_memory':True}
    
    # create dataloader
    trainLoader = torch.utils.data.DataLoader(datasetTrain,**paramsTrain)
    valLoader = torch.utils.data.DataLoader(datasetValidate,**paramsValidate)

    # create the network
    net = createDiscriminator()
    
    # loss criterion and optimizer
    criterion = nn.BCEWithLogitsLoss()
    #optimizer = optim.Adam(net.parameters(),lr=0.05)
    optimizer = optim.SGD(net.parameters(),lr=0.005,momentum=0.9)
   
    net.to(device)
    train_loss_list = []
    val_loss_list = []
    
    for epoch in range(numEpochs):
        print("Training...")


        for step,data in enumerate(trainLoader):
           
            # extracts images and labels and moves them to gpu
            inputs,labels = extractData(data,device)                        
            
            optimizer.zero_grad()

            outputs = net(inputs)
            loss = criterion(outputs,labels)
            loss.backward()
            optimizer.step()
           
            train_loss_list.append(loss.cpu().detach().numpy())
            
            if step % 10 == 0:
                logStatus('Training',device,epoch,step,loss,labels,outputs) 
            
            if step == 100:
                break

        # remove grad and perform validation
        with torch.no_grad():

            for step,data in enumerate(valLoader):
                
                inputs,labels = extractData(data,device)                       
                
                # change network to evaluation mode
                net.eval()

                outputs = net(inputs)
                loss = criterion(outputs,labels)
                
                val_loss_list.append(loss.cpu().detach().numpy())

                if step % 10 == 0:
                    logStatus('Validation',device,epoch,step,loss,labels,outputs) 
               

    # save the trained model
    torch.save(net.state_dict(),'discriminator.pth')
    print("NETWORK SAVED")
    csvFromList(train_loss_list,'training_loss.csv')
    csvFromList(val_loss_list,'validation_loss.csv')
    print("Finished training")
#
#
#            

if __name__=="__main__":
    main()
